{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:12:44.307130Z",
          "iopub.status.busy": "2025-02-01T06:12:44.306857Z",
          "iopub.status.idle": "2025-02-01T06:13:20.391840Z",
          "shell.execute_reply": "2025-02-01T06:13:20.390819Z",
          "shell.execute_reply.started": "2025-02-01T06:12:44.307100Z"
        },
        "id": "Dv9LqzagR6kw",
        "outputId": "fb2458c5-15ff-4ec9-95ce-3fb30d1ef39a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install unsloth\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:20.393162Z",
          "iopub.status.busy": "2025-02-01T06:13:20.392912Z",
          "iopub.status.idle": "2025-02-01T06:13:20.717520Z",
          "shell.execute_reply": "2025-02-01T06:13:20.716838Z",
          "shell.execute_reply.started": "2025-02-01T06:13:20.393141Z"
        },
        "id": "IhP0tdOyR6kx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1USL7uERSYlr",
        "outputId": "cc3acb33-e26d-437a-e1b0-94bbabc57afa"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c image-processing-thai-language-image-captioning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC0S_MNWSaAX",
        "outputId": "be7ed9ae-5b8d-4ecf-92a9-e71d71319c07"
      },
      "outputs": [],
      "source": [
        "!unzip image-processing-thai-language-image-captioning.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh3mDIDYScrM"
      },
      "outputs": [],
      "source": [
        "!rm image-processing-thai-language-image-captioning.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSPlvueVSgCT",
        "outputId": "2977e671-9cde-457e-e6f6-933ea8ad6a7c"
      },
      "outputs": [],
      "source": [
        "!wget http://images.cocodataset.org/zips/train2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uomko3OYShnl",
        "outputId": "59be6111-76cf-4dfa-a403-6d1df6e6a458"
      },
      "outputs": [],
      "source": [
        "!wget http://images.cocodataset.org/zips/val2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj1JnUbsSh9R",
        "outputId": "8d3d6cff-7da7-4c4b-a2bd-c3756e90e843"
      },
      "outputs": [],
      "source": [
        "!unzip train2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_X7lp0rSkJT",
        "outputId": "54d7d274-ecfd-435b-a385-0358130d8d2b"
      },
      "outputs": [],
      "source": [
        "!unzip val2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NYr46mZSmJx"
      },
      "outputs": [],
      "source": [
        "!rm train2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8pRN2r8Soaz"
      },
      "outputs": [],
      "source": [
        "!rm val2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:20.718556Z",
          "iopub.status.busy": "2025-02-01T06:13:20.718230Z",
          "iopub.status.idle": "2025-02-01T06:13:22.084265Z",
          "shell.execute_reply": "2025-02-01T06:13:22.083575Z",
          "shell.execute_reply.started": "2025-02-01T06:13:20.718537Z"
        },
        "id": "ktTSoQMNR6kx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the train JSON file\n",
        "with open(\"capgen_v1.0_train.json\", \"r\", encoding=\"utf-8\") as file:\n",
        "    train_data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:22.086699Z",
          "iopub.status.busy": "2025-02-01T06:13:22.086401Z",
          "iopub.status.idle": "2025-02-01T06:13:22.162083Z",
          "shell.execute_reply": "2025-02-01T06:13:22.161470Z",
          "shell.execute_reply.started": "2025-02-01T06:13:22.086679Z"
        },
        "id": "1xM1tm8xR6kx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the val JSON file\n",
        "with open(\"capgen_v1.0_val.json\", \"r\", encoding=\"utf-8\") as file:\n",
        "    val_data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:22.163543Z",
          "iopub.status.busy": "2025-02-01T06:13:22.163318Z",
          "iopub.status.idle": "2025-02-01T06:13:23.254833Z",
          "shell.execute_reply": "2025-02-01T06:13:23.253974Z",
          "shell.execute_reply.started": "2025-02-01T06:13:22.163526Z"
        },
        "id": "E0mW-vtvR6kx",
        "outputId": "a63f9116-5ce0-4d13-a4d0-485839d8a646",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "train_replacements = {\n",
        "    \"coco/train2017/\": \"./train2017/\",\n",
        "    \"ipu24/train/\": \"./train/train/\",\n",
        "}\n",
        "\n",
        "val_replacements = {\n",
        "    \"coco/val2017/\": \"./val2017/\",\n",
        "    \"ipu24/val/\": \"./val/val/\",\n",
        "}\n",
        "\n",
        "# Apply replacements dynamically\n",
        "train_updated_data = {}\n",
        "val_updated_data = {}\n",
        "unreplaced_count_train = 0\n",
        "unreplaced_paths_train = []\n",
        "unreplaced_count_val = 0\n",
        "unreplaced_paths_val = []\n",
        "\n",
        "for path, captions in train_data.items():\n",
        "    original_path = path  # Store original path\n",
        "    replaced = False\n",
        "\n",
        "    for old, new in train_replacements.items():\n",
        "        if old in path:\n",
        "            path = path.replace(old, new)\n",
        "            replaced = True\n",
        "\n",
        "    if not replaced:\n",
        "        unreplaced_count_train += 1\n",
        "        unreplaced_paths_train.append(original_path)\n",
        "\n",
        "    train_updated_data[path] = captions\n",
        "\n",
        "for path, captions in val_data.items():\n",
        "    original_path = path  # Store original path\n",
        "    replaced = False\n",
        "\n",
        "    for old, new in val_replacements.items():\n",
        "        if old in path:\n",
        "            path = path.replace(old, new)\n",
        "            replaced = True\n",
        "\n",
        "    if not replaced:\n",
        "        unreplaced_count_val += 1\n",
        "        unreplaced_paths_val.append(original_path)\n",
        "\n",
        "    val_updated_data[path] = captions\n",
        "\n",
        "# Save updated JSON\n",
        "with open(\"capgen_v1.0_train_modified.json\", \"w\", encoding=\"utf-8\") as file:\n",
        "    json.dump(train_updated_data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "with open(\"capgen_v1.0_val_modified.json\", \"w\", encoding=\"utf-8\") as file:\n",
        "    json.dump(val_updated_data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    \"unreplaced_count_train\": unreplaced_count_train,\n",
        "    \"unreplaced_paths_train\": unreplaced_paths_train,\n",
        "    \"unreplaced_count_val\": unreplaced_count_val,\n",
        "    \"unreplaced_paths_val\": unreplaced_paths_val,\n",
        "}\n",
        "\n",
        "print(\"Custom modified JSONs saved successfully!\")\n",
        "print(f\"Unreplaced train paths count: {unreplaced_count_train}\")\n",
        "print(f\"Unreplaced val paths count: {unreplaced_count_val}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYMSg04OnRTl",
        "outputId": "c2303240-8dc1-4826-b424-87ae98c2f2f7"
      },
      "outputs": [],
      "source": [
        "len(train_updated_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:23.256064Z",
          "iopub.status.busy": "2025-02-01T06:13:23.255757Z",
          "iopub.status.idle": "2025-02-01T06:13:23.260005Z",
          "shell.execute_reply": "2025-02-01T06:13:23.259118Z",
          "shell.execute_reply.started": "2025-02-01T06:13:23.256034Z"
        },
        "id": "bv-jEzRPR6kx",
        "outputId": "18a5d448-e4ca-407a-f74d-b7362068fa37",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for i in val_updated_data.items():\n",
        "    print(i)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:23.260897Z",
          "iopub.status.busy": "2025-02-01T06:13:23.260717Z",
          "iopub.status.idle": "2025-02-01T06:13:23.384377Z",
          "shell.execute_reply": "2025-02-01T06:13:23.383556Z",
          "shell.execute_reply.started": "2025-02-01T06:13:23.260881Z"
        },
        "id": "SyVsI6FKR6kx",
        "outputId": "9447d5c1-c452-4990-c13c-49da467f7752",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(list(train_updated_data.items())[:3])  # Show first 3 items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:23.385537Z",
          "iopub.status.busy": "2025-02-01T06:13:23.385271Z",
          "iopub.status.idle": "2025-02-01T06:13:23.401247Z",
          "shell.execute_reply": "2025-02-01T06:13:23.400589Z",
          "shell.execute_reply.started": "2025-02-01T06:13:23.385516Z"
        },
        "id": "lrtCoAEXR6ky",
        "outputId": "f37b4220-d58a-499c-d353-7879843ebab1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(list(val_updated_data.items())[:3])  # Show first 3 items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:23.402178Z",
          "iopub.status.busy": "2025-02-01T06:13:23.401999Z",
          "iopub.status.idle": "2025-02-01T06:13:23.458696Z",
          "shell.execute_reply": "2025-02-01T06:13:23.458112Z",
          "shell.execute_reply.started": "2025-02-01T06:13:23.402162Z"
        },
        "id": "9U8Wmo7bR6ky",
        "outputId": "d4103237-2c99-43ce-a176-8fb03f06ee6c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ## Explore the data by finding the first index\n",
        "# for i in train_updated_data.keys():\n",
        "#     print(i)\n",
        "#     x = i\n",
        "#     image = Image.open(i)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:23.459614Z",
          "iopub.status.busy": "2025-02-01T06:13:23.459373Z",
          "iopub.status.idle": "2025-02-01T06:13:23.541075Z",
          "shell.execute_reply": "2025-02-01T06:13:23.540287Z",
          "shell.execute_reply.started": "2025-02-01T06:13:23.459591Z"
        },
        "id": "WiiHX93DR6ky",
        "outputId": "04fa7832-1256-4545-84bc-40356a1e23b0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Image.open(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:23.542015Z",
          "iopub.status.busy": "2025-02-01T06:13:23.541833Z",
          "iopub.status.idle": "2025-02-01T06:13:23.546557Z",
          "shell.execute_reply": "2025-02-01T06:13:23.545856Z",
          "shell.execute_reply.started": "2025-02-01T06:13:23.541999Z"
        },
        "id": "9nv9FWOhR6ky",
        "outputId": "436ba6bc-6f3a-49e4-ca9a-e2e145e1bf3e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# train_updated_data[x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:23.547520Z",
          "iopub.status.busy": "2025-02-01T06:13:23.547283Z",
          "iopub.status.idle": "2025-02-01T06:13:23.573542Z",
          "shell.execute_reply": "2025-02-01T06:13:23.572860Z",
          "shell.execute_reply.started": "2025-02-01T06:13:23.547489Z"
        },
        "id": "eNKLXkfhR6ky",
        "outputId": "e9322537-55d0-4d29-88ef-89c5ba7354f5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ## Explore the data by finding the first index\n",
        "# for i in val_updated_data.keys():\n",
        "#     print(i)\n",
        "#     y = i\n",
        "#     image = Image.open(i)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:23.576184Z",
          "iopub.status.busy": "2025-02-01T06:13:23.576001Z",
          "iopub.status.idle": "2025-02-01T06:13:23.625850Z",
          "shell.execute_reply": "2025-02-01T06:13:23.625057Z",
          "shell.execute_reply.started": "2025-02-01T06:13:23.576168Z"
        },
        "id": "gG7YM74pR6ky",
        "outputId": "fa01b275-2e9a-4f07-bbfc-40d6770e52e7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Image.open(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:23.627060Z",
          "iopub.status.busy": "2025-02-01T06:13:23.626871Z",
          "iopub.status.idle": "2025-02-01T06:13:23.631367Z",
          "shell.execute_reply": "2025-02-01T06:13:23.630527Z",
          "shell.execute_reply.started": "2025-02-01T06:13:23.627044Z"
        },
        "id": "bq_jNpMBR6ky",
        "outputId": "c7353bc9-04b4-4b3d-f224-7f69b82ab69e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# val_updated_data[y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:23.632560Z",
          "iopub.status.busy": "2025-02-01T06:13:23.632275Z",
          "iopub.status.idle": "2025-02-01T06:13:23.644802Z",
          "shell.execute_reply": "2025-02-01T06:13:23.644160Z",
          "shell.execute_reply.started": "2025-02-01T06:13:23.632540Z"
        },
        "id": "6VF_xrZbR6ky",
        "outputId": "e7ddb787-2858-4310-c43c-15792c9a0d9d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# len(train_updated_data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-01T06:13:23.645949Z",
          "iopub.status.busy": "2025-02-01T06:13:23.645664Z",
          "iopub.status.idle": "2025-02-01T06:13:23.658190Z",
          "shell.execute_reply": "2025-02-01T06:13:23.657497Z",
          "shell.execute_reply.started": "2025-02-01T06:13:23.645921Z"
        },
        "id": "SPdQZu6OR6ky",
        "outputId": "c9ab3542-3fa3-41ee-dbbd-39bf16bc931a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# len(val_updated_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwPgznxhTX3B",
        "outputId": "1eff9a7d-2e8b-479b-b326-3e63034e0fbd"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "instruction = \"ได้โปรดคิดคำบรรยายภาพภาษาไทยรูปนี้ให้หน่อย พยายามบอกรายละเอียดของสิ่งต่าง ๆ เหมือนตอนทำโจทย์ Image Captioning\"\n",
        "\n",
        "def convert_to_conversation(sample):\n",
        "    \"\"\"\n",
        "    Converts a sample (with keys \"image_path\" and \"caption\") into\n",
        "    the conversation format expected by UnsLoth.\n",
        "    \"\"\"\n",
        "    conversation = [\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "              {\"type\": \"text\", \"text\": instruction},\n",
        "              {\"type\": \"image\", \"image\": Image.open(sample[\"image_path\"])}  # load image here\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"assistant\",\n",
        "          \"content\": [\n",
        "              {\"type\": \"text\", \"text\": sample[\"caption\"]}\n",
        "          ]\n",
        "        },\n",
        "    ]\n",
        "    return {\"messages\": conversation}\n",
        "\n",
        "# Convert the training data into a list of conversation dictionaries.\n",
        "# Here, we select one random caption per image.\n",
        "converted_train_dataset = [\n",
        "    convert_to_conversation({\"image_path\": img_path, \"caption\": random.choice(captions)})\n",
        "    for img_path, captions in tqdm(train_updated_data.items(), desc=\"Converting Train Data\")\n",
        "]\n",
        "\n",
        "# converted_val_dataset = [\n",
        "#     convert_to_conversation({\"image_path\": img_path, \"caption\": random.choice(captions)})\n",
        "#     for img_path, captions in tqdm(train_updated_data.items(), desc=\"Converting Val Data\")\n",
        "# ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDiPZbnVtNzA",
        "outputId": "b48e3c79-c307-467e-89ab-b92c03328ab7"
      },
      "outputs": [],
      "source": [
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq0OXuxEShCF"
      },
      "outputs": [],
      "source": [
        "# del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptbgau6xTZy-",
        "outputId": "afe0b23b-dc6d-4d09-fc68-0d7c5dc68b51"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastVisionModel # FastLanguageModel for LLMs\n",
        "import torch\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Llama-3.2-11B-Vision-Instruct-bnb-4bit\", # Llama 3.2 vision support\n",
        "    \"unsloth/Llama-3.2-11B-Vision-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-90B-Vision-Instruct-bnb-4bit\", # Can fit in a 80GB card!\n",
        "    \"unsloth/Llama-3.2-90B-Vision-bnb-4bit\",\n",
        "\n",
        "    \"unsloth/Pixtral-12B-2409-bnb-4bit\",              # Pixtral fits in 16GB!\n",
        "    \"unsloth/Pixtral-12B-Base-2409-bnb-4bit\",         # Pixtral base model\n",
        "\n",
        "    \"unsloth/Qwen2-VL-2B-Instruct-bnb-4bit\",          # Qwen2 VL support\n",
        "    \"unsloth/Qwen2-VL-7B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Qwen2-VL-72B-Instruct-bnb-4bit\",\n",
        "\n",
        "    \"unsloth/llava-v1.6-mistral-7b-hf-bnb-4bit\",      # Any Llava variant works!\n",
        "    \"unsloth/llava-1.5-7b-hf-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "    \"unsloth/Qwen2-VL-2B-Instruct-bnb-4bit\",\n",
        "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTFfn0jTTbod",
        "outputId": "7ece5ed0-fca6-447d-f599-bba24c84c936"
      },
      "outputs": [],
      "source": [
        "model = FastVisionModel.get_peft_model(\n",
        "    model,\n",
        "    finetune_vision_layers     = True, # False if not finetuning vision layers\n",
        "    finetune_language_layers   = True, # False if not finetuning language layers\n",
        "    finetune_attention_modules = True, # False if not finetuning attention layers\n",
        "    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n",
        "\n",
        "    r = 256,           # The larger, the higher the accuracy, but might overfit\n",
        "    lora_alpha = 256,  # Recommended alpha == r at least\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    random_state = 42,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        "    # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NVFP_6uTdyL"
      },
      "outputs": [],
      "source": [
        "from unsloth import is_bf16_supported\n",
        "from unsloth.trainer import UnslothVisionDataCollator\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "FastVisionModel.for_training(model) # Enable for training!\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = UnslothVisionDataCollator(model, tokenizer), # Must use!\n",
        "    train_dataset = converted_train_dataset,\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 4,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 100,\n",
        "        # num_train_epochs = 2, # Set this instead of max_steps for full training runs\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bf16_supported(),\n",
        "        bf16 = is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 42,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\",     # For Weights and Biases\n",
        "\n",
        "        # You MUST put the below items for vision finetuning:\n",
        "        remove_unused_columns = False,\n",
        "        dataset_text_field = \"\",\n",
        "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
        "        dataset_num_proc = 4,\n",
        "        max_seq_length = 64,\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JgXt7-Ua5TCI",
        "outputId": "63059595-b282-45fe-cef5-d1dc44968008"
      },
      "outputs": [],
      "source": [
        "train_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNnF2YEdwk6f",
        "outputId": "6d554d31-4de8-4602-902c-93c9658f2404"
      },
      "outputs": [],
      "source": [
        "FastVisionModel.for_inference(model) # Enable for inference!\n",
        "\n",
        "image = Image.open(\"/content/test/test/00011.jpg\")\n",
        "instruction = \"ได้โปรดคิดคำบรรยายภาพภาษาไทยรูปนี้ให้หน่อย พยายามบอกรายละเอียดของสิ่งต่าง ๆ เหมือนตอนทำโจทย์ Image Captioning\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"image\"},\n",
        "        {\"type\": \"text\", \"text\": instruction}\n",
        "    ]}\n",
        "]\n",
        "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
        "inputs = tokenizer(\n",
        "    image,\n",
        "    input_text,\n",
        "    add_special_tokens = False,\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 60,\n",
        "                   use_cache = True, temperature = 0.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj0-cO8SCR9T",
        "outputId": "6112294c-a7ea-4c86-9011-316cbc2bc547"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import csv\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from unsloth import FastVisionModel\n",
        "import torch\n",
        "\n",
        "# Load the sample submission\n",
        "sample_submission_file = \"sample_submission.csv\"\n",
        "output_file = \"submission.csv\"\n",
        "\n",
        "# Copy the sample submission file to create submission.csv\n",
        "shutil.copy(sample_submission_file, output_file)\n",
        "\n",
        "# Read the sample submission file\n",
        "df_submission = pd.read_csv(output_file)\n",
        "\n",
        "# Extract image IDs from the CSV\n",
        "image_ids = df_submission[\"image_id\"].tolist()\n",
        "\n",
        "# 1) Enable your vision model for inference\n",
        "FastVisionModel.for_inference(model)\n",
        "\n",
        "BATCH_SIZE = 4  # <-- pick a suitable batch size for your GPU\n",
        "output_rows = []\n",
        "\n",
        "# Process images in batches\n",
        "for i in tqdm(range(0, len(image_ids), BATCH_SIZE), desc=\"Generating captions in batches\"):\n",
        "    batch_ids = image_ids[i : i + BATCH_SIZE]\n",
        "\n",
        "    # Prepare images and prompts\n",
        "    images = []\n",
        "    prompts = []\n",
        "    valid_ids = []  # Store only IDs that exist as images\n",
        "\n",
        "    for image_id in batch_ids:\n",
        "        img_path = f\"/content/test/test/{image_id:05d}.jpg\"  # Ensure correct filename formatting\n",
        "\n",
        "        if os.path.exists(img_path):  # Check if the image exists\n",
        "            valid_ids.append(image_id)\n",
        "\n",
        "            # Open image\n",
        "            image = Image.open(img_path)\n",
        "            images.append(image)\n",
        "\n",
        "            # Build an instruction for each image\n",
        "            instruction = \"ได้โปรดคิดคำบรรยายภาพภาษาไทยรูปนี้ให้หน่อย พยายามบอกรายละเอียดของสิ่งต่าง ๆ เหมือนตอนทำโจทย์ Image Captioning\"\n",
        "            messages = [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"image\"},\n",
        "                        {\"type\": \"text\", \"text\": instruction}\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            # Convert messages to final text\n",
        "            input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
        "            prompts.append(input_text)\n",
        "\n",
        "    if not images:\n",
        "        continue  # Skip batch if no valid images found\n",
        "\n",
        "    # 4) Tokenize the entire batch at once\n",
        "    inputs = tokenizer(\n",
        "        images,  # list of PIL images\n",
        "        prompts,  # list of strings\n",
        "        add_special_tokens=False,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # 5) Generate captions for the batch\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=60,\n",
        "            use_cache=True,\n",
        "            temperature=0.5,\n",
        "            min_p=0.1\n",
        "        )\n",
        "\n",
        "    # 6) Decode each output\n",
        "    for idx, out_ids in enumerate(output_ids):\n",
        "        generated_text = tokenizer.decode(out_ids, skip_special_tokens=True)\n",
        "        generated_text = generated_text.replace(\"<|im_end|>\", \"\").strip()\n",
        "\n",
        "        # Store predictions\n",
        "        output_rows.append((valid_ids[idx], generated_text))\n",
        "\n",
        "# Update the CSV with new captions\n",
        "df_submission.set_index(\"image_id\", inplace=True)\n",
        "for image_id, caption in output_rows:\n",
        "    df_submission.loc[image_id, \"caption\"] = caption\n",
        "\n",
        "# Save the updated submission file\n",
        "df_submission.to_csv(output_file)\n",
        "\n",
        "print(f\"Done! Captions saved in {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "jHtoWoto8rt1",
        "outputId": "202e7bec-573b-4eec-98aa-7fa97586653c"
      },
      "outputs": [],
      "source": [
        "df_submission.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzobWniDoLhr"
      },
      "outputs": [],
      "source": [
        "(pd.read_csv(\"cleaned_submission.csv\").fillna(\"คือ\")).to_csv(\"submission2.csv\",index=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 10825598,
          "sourceId": 91535,
          "sourceType": "competition"
        },
        {
          "datasetId": 857191,
          "sourceId": 1462296,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30839,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
